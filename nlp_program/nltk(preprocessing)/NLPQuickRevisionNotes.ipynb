{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b735f54-f299-4814-b7b4-78062e44baf0",
   "metadata": {},
   "source": [
    "\n",
    "## üß† Natural Language Processing (NLP) - Comprehensive Notes üöÄ\n",
    "\n",
    "## **1Ô∏è‚É£ Introduction to NLP**\n",
    "### üîπ What is NLP?\n",
    "- NLP (Natural Language Processing) is a field of AI that enables computers to understand, interpret, and respond to human language.\n",
    "- It is a combination of **linguistics, computer science, and machine learning**.\n",
    "- Applications include **chatbots, translation, sentiment analysis, spam detection, voice assistants, etc.**\n",
    "\n",
    "### üîπ Key Challenges in NLP:\n",
    "- **Ambiguity**: \"I saw a man with a telescope\" (Who has the telescope?).\n",
    "- **Synonyms & Homonyms**: Different words with the same meaning (happy, joyful).\n",
    "- **Context Understanding**: \"Apple is a company\" vs. \"I ate an apple.\"\n",
    "- **Sarcasm & Idioms**: \"Oh, great! Another bug in the code.\"\n",
    "\n",
    "---\n",
    "\n",
    "## **2Ô∏è‚É£ Text Preprocessing**\n",
    "### üîπ Why is Preprocessing Needed?\n",
    "- Raw text contains **punctuations, special characters, stopwords**, etc., which need to be cleaned.\n",
    "- Preprocessing helps in **better feature extraction & model performance**.\n",
    "\n",
    "### **üîπ Steps in Text Preprocessing**\n",
    "#### ‚úÖ **1. Tokenization**\n",
    "- Breaking text into smaller units (**words or sentences**).\n",
    "```python\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "text = \"NLP is amazing! Let's learn it.\"\n",
    "print(word_tokenize(text))  # ['NLP', 'is', 'amazing', '!', 'Let', \"'s\", 'learn', 'it', '.']\n",
    "print(sent_tokenize(text))  # [\"NLP is amazing!\", \"Let's learn it.\"]\n",
    "```\n",
    "\n",
    "#### ‚úÖ **2. Stopword Removal**\n",
    "- Removing common words that do not add value (**\"is\", \"the\", \"and\"**).\n",
    "```python\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')  # List of stopwords\n",
    "```\n",
    "\n",
    "#### ‚úÖ **3. Stemming**\n",
    "- Reducing words to their root form (**running ‚Üí run**).\n",
    "```python\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "print(ps.stem(\"running\"))  # 'run'\n",
    "```\n",
    "\n",
    "#### ‚úÖ **4. Lemmatization**\n",
    "- Converts words to base form while keeping meaning intact (**better ‚Üí good**).\n",
    "```python\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize(\"running\", pos=\"v\"))  # 'run'\n",
    "```\n",
    "\n",
    "#### ‚úÖ **5. Removing Special Characters & Punctuation**\n",
    "```python\n",
    "import re\n",
    "text = \"Hello!! This is NLP 101.\"\n",
    "clean_text = re.sub(r'[^a-zA-Z ]', '', text)  # Remove special characters\n",
    "print(clean_text)  # 'Hello This is NLP '\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **3Ô∏è‚É£ N-Grams**\n",
    "### üîπ What are N-Grams?\n",
    "- **N-Grams** are sequences of 'n' words in a sentence:\n",
    "  - **Unigram** ‚Üí [\"I\", \"love\", \"NLP\"]\n",
    "  - **Bigram** ‚Üí [\"I love\", \"love NLP\"]\n",
    "  - **Trigram** ‚Üí [\"I love NLP\"]\n",
    "```python\n",
    "from nltk.util import ngrams\n",
    "tokens = word_tokenize(\"I love NLP\")\n",
    "bigrams = list(ngrams(tokens, 2))\n",
    "print(bigrams)  # [('I', 'love'), ('love', 'NLP')]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **4Ô∏è‚É£ Feature Extraction**\n",
    "### **üîπ Bag of Words (BoW)**\n",
    "- Represents text as a matrix of word occurrences.\n",
    "```python\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\"NLP is great\", \"Machine learning is fun\"]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names_out())  # ['fun', 'great', 'is', 'learning', 'machine', 'nlp']\n",
    "```\n",
    "\n",
    "### **üîπ TF-IDF (Term Frequency-Inverse Document Frequency)**\n",
    "- Highlights important words while down-weighting common ones.\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **5Ô∏è‚É£ Word Embeddings**\n",
    "### üîπ Word2Vec (Google) & GloVe (Stanford)\n",
    "- Converts words into numerical representations (vectors).\n",
    "```python\n",
    "from gensim.models import Word2Vec\n",
    "sentences = [[\"NLP\", \"is\", \"fun\"], [\"Deep\", \"learning\", \"is\", \"powerful\"]]\n",
    "model = Word2Vec(sentences, min_count=1)\n",
    "print(model.wv.most_similar(\"NLP\"))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6Ô∏è‚É£ Text Classification**\n",
    "- Used in **spam detection, sentiment analysis, etc.**\n",
    "```python\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts = [\"Buy now\", \"Limited offer\", \"Hello friend\", \"See you soon\"]\n",
    "labels = [1, 1, 0, 0]  # 1=Spam, 0=Not Spam\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, labels)\n",
    "\n",
    "new_text = vectorizer.transform([\"Limited time deal\"])\n",
    "print(clf.predict(new_text))  # 1 (Spam)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **7Ô∏è‚É£ Named Entity Recognition (NER)**\n",
    "- Identifies names, locations, dates, etc.\n",
    "```python\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying a UK startup for $1 billion\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)  # Apple ORG, UK GPE, $1 billion MONEY\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **8Ô∏è‚É£ Sentiment Analysis**\n",
    "- Determines if text is **positive, negative, or neutral**.\n",
    "```python\n",
    "from textblob import TextBlob\n",
    "text = \"I love NLP!\"\n",
    "blob = TextBlob(text)\n",
    "print(blob.sentiment.polarity)  # 0.5 (positive)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **9Ô∏è‚É£ Transformer Models (BERT, GPT)**\n",
    "### **üîπ BERT (Bidirectional Encoder Representations from Transformers)**\n",
    "- Pre-trained model for **question answering, sentiment analysis**.\n",
    "```python\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "print(classifier(\"NLP is awesome!\"))  # [{'label': 'POSITIVE', 'score': 0.999}]\n",
    "```\n",
    "\n",
    "### **üîπ GPT (Generative Pre-trained Transformer)**\n",
    "- Used for **text generation (ChatGPT, AI Chatbots)**.\n",
    "```python\n",
    "from transformers import pipeline\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "print(generator(\"Once upon a time\", max_length=30))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **üîü NLP Applications**\n",
    "‚úÖ **Chatbots (Siri, Alexa, ChatGPT)**  \n",
    "‚úÖ **Machine Translation (Google Translate)**  \n",
    "‚úÖ **Speech Recognition (Voice Assistants)**  \n",
    "‚úÖ **Fake News Detection**  \n",
    "‚úÖ **Text Summarization**  \n",
    "‚úÖ **Autocorrect & Spell Checking**  \n",
    "\n",
    "---\n",
    "\n",
    "# üéØ **Final Tips**\n",
    "- Practice with **real-world datasets** (Twitter sentiment analysis, spam detection, etc.).\n",
    "- Use pre-trained models like **BERT & GPT**.\n",
    "- Deploy NLP models using **Flask / FastAPI / Streamlit**.\n",
    "\n",
    "---\n",
    "\n",
    "üî• **Master NLP & Build AI-powered Applications! üöÄ**\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0725b3b-64b4-4d7e-99cb-a0909dad6242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
